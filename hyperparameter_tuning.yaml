searchSpace:
  learning_rate: 
    _type: uniform
    _value: [ 0.00001, 0.1 ]
  batch_size:
      _type: choice
      _value: [16, 32, 64, 128]
  optimizer: 
    _type: choice
    _value: [RMSprop, Adam, NAdam, RAdam]
  window_size:
    _type: randint
    _value: [ 30, 60, 90, 120, 150, 180, 360, 720, 1080, 1200, 1800, 2400, 3600 ]
  scaler: 
    _type: choice
    _value: [RMSprop, Adam, NAdam, RAdam]

  ## CNN
  out_features: 
    _type: uniform
    _value: [ 0, 1 ]
  pooling_sizes:
    _type: randint
    _value: [ 1, 5 ]
  kernel_sizes:
    _type: randint
    _value: [ 1, 10 ]
  strides:
    _type: uniform
    _value: [ 1, 5 ]
  dilations:
    _type: randint
    _value: [ 1, 5 ]
  dropout_rates:
    _type: uniform
    _value: [ 0, 1 ]
  fc_outputs:
    _type: choice
    _value: [ [50, 1], [100, 1] ] 
  fc_dropout_rates:
    _type: uniform
    _value: [ 0, 1 ]

  ## LSTM
  # out_features: 
  #   _type: uniform
  #   _value: [ [50, 20], [100, 20] ]
  # bidirectional:
  #   _type: choice
  #   _value: [ True, False ]
  # dropout_rates:
  #   _type: uniform
  #   _value: [ 0, 1 ]
  # fc_outputs:
  #   _type: choice
  #   _value: [ [30, 1], [100, 1], [200, 50, 1]]
  # fc_dropout_rates:
  #   _type: uniform
  #   _value: [ 0, 1 ]

  ## TSMixer
  # n_block:
  #   _type: randint
  #   _value: [ 2, 32 ]
  # dropout_rates:
  #   _type: uniform
  #   _value: [ 0, 1 ]
  # ff_dim:
  #   _type: choice
  #   _value: [ 32, 64, 128, 256, 512, 1024, 2048, 4096 ]



# experimentName: ale
trainingService:
  platform: remote
  machineList:
  - host: 
    user: 
    password: 
    useActiveGpu: true
    # gpuIndices: 0
    pythonPath: /home/user/anaconda3/envs/nni/bin
nniManagerIp: 
trialCodeDirectory: .
trialCommand: python script.py train --exp_name=nni
trialConcurrency: 4
trialGpuNumber: 1
tuner:
  name: TPE
  classArgs:
    optimize_mode: maximize
# debug: true
